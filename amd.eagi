#!/home/ec2-user/miniconda3/bin/python -u

#print("exec VERBOSE \"Running PYTHON AMD RECORDING script...\"")

import time
import datetime
from asterisk.agi import *
import librosa
import numpy as np
import math

now = datetime.datetime.now()
RECORD_DURATION = 2.5

#print("exec VERBOSE \"Initializing program...\"")

# const
PREDICTION_BUFFER_LENGTH = 24000 # number of audio samples the prediction takes
def melspec(librosa_audio):
    return librosa.power_to_db(librosa.feature.melspectrogram(y=librosa_audio, sr=8000, n_fft=200, hop_length=80), ref=np.max).transpose()

def get_rms(audio):
    int_timeseries = np.rint(32768.0 * audio).astype(np.int32)
    squared_timeseries = np.square(int_timeseries).astype(np.float32)
    scaled_square_timeseries = squared_timeseries / len(audio)
    mean_square_timeseries = np.sum(scaled_square_timeseries)
    rms = int(math.sqrt(mean_square_timeseries))
    return rms

def get_dbfs(audio):
    rms = get_rms(audio)
    assert rms > 0, f"RMS <= 0: {rms}"
    ratio = float(rms) / (2 ** 15)
    return 20 * math.log(ratio, 10)

def apply_gain(audio, gain_db):
    return np.clip(audio * (10 ** (float(gain_db) / 20.0)), -1.0, 1.0)

def normalize(audio, target_dbfs=-20):
    change_in_dBFS = target_dbfs - get_dbfs(audio)
    return apply_gain(audio, change_in_dBFS)

agi = AGI()

prediction_window = 1.5 #args.pred_window
prediction_interval = 0.5 #args.pred_interval
#print("exec VERBOSE \"Starting AMD PYTHON v2 script at " + datetime.datetime.now().strftime('%b-%d-%I%M%p-%G') + "...\"")

libmodel = np.ctypeslib.load_library('libmodel.so', '/home/ec2-user/amd/')
libmodel.run.argtypes = [
    np.ctypeslib.ndpointer(np.float32, ndim=3, shape=(1, 301, 128), flags=('c', 'a')),
    np.ctypeslib.ndpointer(np.float32, ndim=2, shape=(1, 3), flags=('c', 'a', 'w')),
    np.ctypeslib.ctypes.c_int,
    np.ctypeslib.ctypes.c_int]

def predict(x):
    x = np.require(x, np.float32, ('c', 'a'))
    y = np.require(np.zeros((1, 3)), np.float32, ('c', 'a', 'w'))
    libmodel.run(x, y, x.size, y.size)
    return y

#print("exec VERBOSE \"Starting AMD PYTHON detector at " + datetime.datetime.now().strftime('%b-%d-%I%M%p-%G') + "...\"")

print("STREAM FILE privacy-thankyou \"\"")
audio_fh = open("/dev/fd/3", "rb")

audio_length = 0.0
audio_timeseries = []

start_time = time.time()
while time.time() - start_time < 5.0:
    buffer_read_size = int(prediction_window * 2 * 8000.0) if audio_length == 0.0 else int(prediction_interval * 2 * 8000)
    buffer_audio = audio_fh.read(buffer_read_size)
    read_length = len(buffer_audio)/(2.0*8000.0)
    audio_length += read_length

    frame = librosa.util.buf_to_float(buffer_audio, dtype=np.float32)
    audio_timeseries.append(frame)

    X_audio = np.concatenate(audio_timeseries)
    if X_audio.shape[0] > PREDICTION_BUFFER_LENGTH:
        X_audio = X_audio[-PREDICTION_BUFFER_LENGTH:]

    X_audio, index = librosa.effects.trim(X_audio, top_db=20, frame_length=800, hop_length=80)

    if get_rms(X_audio) < 1e-9:
        continue
    if len(X_audio) < 8000:
        continue

    X_audio = normalize(X_audio)

    X_audio = np.append(X_audio, np.zeros((PREDICTION_BUFFER_LENGTH - X_audio.shape[0],), dtype=np.float32))
    X = melspec(X_audio)

    # predict model on X
    assert X.shape == (301, 128)
    X = X.reshape(1, 301, 128)
    y_hat = np.round(predict(X).reshape(3,), 2).astype(np.float32)

    print("exec VERBOSE \"RECEIVED PREDICTION VECTOR " + str(audio_length) + ":" + str(y_hat) + "\"")

    if len(X_audio) > int(0.9 * 8000 * RECORD_DURATION):
        break

print("SET VARIABLE AMD_RESULT " + str(2))
X_audio = np.concatenate(audio_timeseries)
librosa.output.write_wav(f"/home/ec2-user/amd/recordings/recording_{now:%m-%d-%Y_%H-%M-%S}@{str(agi.env['agi_channel'].split('-', 1)[1].split('@', 1)[0])}.wav", X_audio, 8000)

print("exec VERBOSE \"FINISHING AMD script at " + datetime.datetime.now().strftime('%b-%d-%I%M%p-%G') + "...\"")
audio_fh.close()
